{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving SSD outputs to: outputs/\n",
      "--------------------Config file below--------------------\n",
      "{ 'anchors': { '_target_': <class 'ssd.modeling.anchor_boxes.AnchorBoxes'>,\n",
      "               'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
      "               'feature_sizes': [ [38, 38],\n",
      "                                  [19, 19],\n",
      "                                  [10, 10],\n",
      "                                  [5, 5],\n",
      "                                  [3, 3],\n",
      "                                  [1, 1]],\n",
      "               'image_shape': '${train.imshape}',\n",
      "               'min_sizes': [ [15, 15],\n",
      "                              [30, 30],\n",
      "                              [60, 60],\n",
      "                              [111, 111],\n",
      "                              [162, 162],\n",
      "                              [213, 213],\n",
      "                              [264, 264],\n",
      "                              [315, 315]],\n",
      "               'scale_center_variance': 0.1,\n",
      "               'scale_size_variance': 0.2,\n",
      "               'strides': [ [8, 8],\n",
      "                            [16, 16],\n",
      "                            [32, 32],\n",
      "                            [64, 64],\n",
      "                            [100, 100],\n",
      "                            [300, 300]]},\n",
      "  'backbone': { '_target_': <class 'ssd.modeling.backbones.basic.BasicModel'>,\n",
      "                'image_channels': '${train.image_channels}',\n",
      "                'output_channels': [128, 256, 128, 128, 64, 64],\n",
      "                'output_feature_sizes': '${anchors.feature_sizes}'},\n",
      "  'data_train': { 'dataloader': { '_target_': <class 'torch.utils.data.dataloader.DataLoader'>,\n",
      "                                  'batch_size': '${...train.batch_size}',\n",
      "                                  'collate_fn': <function batch_collate at 0x7fdc29da2310>,\n",
      "                                  'dataset': '${..dataset}',\n",
      "                                  'drop_last': True,\n",
      "                                  'num_workers': 4,\n",
      "                                  'pin_memory': True,\n",
      "                                  'shuffle': True},\n",
      "                  'dataset': { '_target_': <class 'ssd.data.mnist.MNISTDetectionDataset'>,\n",
      "                               'data_dir': 'data/mnist_object_detection/train',\n",
      "                               'is_train': True,\n",
      "                               'transform': { '_target_': <class 'torchvision.transforms.transforms.Compose'>,\n",
      "                                              'transforms': [ { '_target_': <class 'ssd.data.transforms.transform.ToTensor'>},\n",
      "                                                              { '_target_': <class 'ssd.data.transforms.target_transform.GroundTruthBoxesToAnchors'>,\n",
      "                                                                'anchors': '${anchors}',\n",
      "                                                                'iou_threshold': 0.5}]}},\n",
      "                  'gpu_transform': { '_target_': <class 'torchvision.transforms.transforms.Compose'>,\n",
      "                                     'transforms': [ { '_target_': <class 'ssd.data.transforms.gpu_transforms.Normalize'>,\n",
      "                                                       'mean': [0.5, 0.5, 0.5],\n",
      "                                                       'std': [ 0.5,\n",
      "                                                                0.5,\n",
      "                                                                0.5]}]}},\n",
      "  'data_val': { 'dataloader': { '_target_': <class 'torch.utils.data.dataloader.DataLoader'>,\n",
      "                                'batch_size': '${...train.batch_size}',\n",
      "                                'collate_fn': <function batch_collate_val at 0x7fdc29da24c0>,\n",
      "                                'dataset': '${..dataset}',\n",
      "                                'num_workers': 4,\n",
      "                                'pin_memory': True,\n",
      "                                'shuffle': False},\n",
      "                'dataset': { '_target_': <class 'ssd.data.mnist.MNISTDetectionDataset'>,\n",
      "                             'data_dir': 'data/mnist_object_detection/val',\n",
      "                             'is_train': False,\n",
      "                             'transform': { '_target_': <class 'torchvision.transforms.transforms.Compose'>,\n",
      "                                            'transforms': [ { '_target_': <class 'ssd.data.transforms.transform.ToTensor'>}]}},\n",
      "                'gpu_transform': { '_target_': <class 'torchvision.transforms.transforms.Compose'>,\n",
      "                                   'transforms': [ { '_target_': <class 'ssd.data.transforms.gpu_transforms.Normalize'>,\n",
      "                                                     'mean': [0.5, 0.5, 0.5],\n",
      "                                                     'std': [0.5, 0.5, 0.5]}]}},\n",
      "  'label_map': { 0: 'background',\n",
      "                 1: '0',\n",
      "                 2: '1',\n",
      "                 3: '2',\n",
      "                 4: '3',\n",
      "                 5: '4',\n",
      "                 6: '5',\n",
      "                 7: '6',\n",
      "                 8: '7',\n",
      "                 9: '8',\n",
      "                 10: '9'},\n",
      "  'loss_objective': { '_target_': <class 'ssd.modeling.ssd_multibox_loss.SSDMultiboxLoss'>,\n",
      "                      'anchors': '${anchors}'},\n",
      "  'model': { '_target_': <class 'ssd.modeling.ssd.SSD300'>,\n",
      "             'anchors': '${anchors}',\n",
      "             'feature_extractor': '${backbone}',\n",
      "             'loss_objective': '${loss_objective}',\n",
      "             'num_classes': 11},\n",
      "  'optimizer': { '_target_': <class 'torch.optim.sgd.SGD'>,\n",
      "                 'lr': 0.005,\n",
      "                 'momentum': 0.9,\n",
      "                 'weight_decay': 0.0005},\n",
      "  'output_dir': PosixPath('outputs/ssd300'),\n",
      "  'run_name': '_ssd300',\n",
      "  'schedulers': { 'linear': { '_target_': <class 'torch.optim.lr_scheduler.LinearLR'>,\n",
      "                              'end_factor': 1,\n",
      "                              'start_factor': 0.1,\n",
      "                              'total_iters': 500},\n",
      "                  'multistep': { '_target_': <class 'torch.optim.lr_scheduler.MultiStepLR'>,\n",
      "                                 'gamma': 0.1,\n",
      "                                 'milestones': []}},\n",
      "  'train': { '_output_dir': PosixPath('outputs'),\n",
      "             'amp': True,\n",
      "             'batch_size': 32,\n",
      "             'epochs': 5,\n",
      "             'image_channels': 3,\n",
      "             'imshape': [300, 300],\n",
      "             'log_interval': 20,\n",
      "             'seed': 0}}\n",
      "--------------------End of config file--------------------\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "SSD300                        Parameters  Buffers  Output shape        Datatype\n",
      "---                           ---         ---      ---                 ---     \n",
      "feature_extractor.Output0.0   1792        -        [1, 64, 300, 300]   float32 \n",
      "feature_extractor.Output0.1   -           -        [1, 64, 300, 300]   float32 \n",
      "feature_extractor.Output0.2   128         129      [1, 64, 300, 300]   float32 \n",
      "feature_extractor.Output0.3   -           -        [1, 64, 150, 150]   float32 \n",
      "feature_extractor.Output0.4   73856       -        [1, 128, 150, 150]  float32 \n",
      "feature_extractor.Output0.5   -           -        [1, 128, 150, 150]  float32 \n",
      "feature_extractor.Output0.6   256         257      [1, 128, 150, 150]  float32 \n",
      "feature_extractor.Output0.7   -           -        [1, 128, 75, 75]    float32 \n",
      "feature_extractor.Output0.8   147584      -        [1, 128, 75, 75]    float32 \n",
      "feature_extractor.Output0.9   -           -        [1, 128, 75, 75]    float32 \n",
      "feature_extractor.Output0.10  256         257      [1, 128, 75, 75]    float32 \n",
      "feature_extractor.Output0.11  147584      -        [1, 128, 38, 38]    float32 \n",
      "feature_extractor.Output0.12  -           -        [1, 128, 38, 38]    float32 \n",
      "feature_extractor.Output1.0   -           -        [1, 128, 38, 38]    float32 \n",
      "feature_extractor.Output1.1   147584      -        [1, 128, 38, 38]    float32 \n",
      "feature_extractor.Output1.2   -           -        [1, 128, 38, 38]    float32 \n",
      "feature_extractor.Output1.3   295168      -        [1, 256, 19, 19]    float32 \n",
      "feature_extractor.Output1.4   -           -        [1, 256, 19, 19]    float32 \n",
      "feature_extractor.Output2.0   -           -        [1, 256, 19, 19]    float32 \n",
      "feature_extractor.Output2.1   590080      -        [1, 256, 19, 19]    float32 \n",
      "feature_extractor.Output2.2   -           -        [1, 256, 19, 19]    float32 \n",
      "feature_extractor.Output2.3   295040      -        [1, 128, 10, 10]    float32 \n",
      "feature_extractor.Output2.4   -           -        [1, 128, 10, 10]    float32 \n",
      "feature_extractor.Output3.0   -           -        [1, 128, 10, 10]    float32 \n",
      "feature_extractor.Output3.1   147584      -        [1, 128, 10, 10]    float32 \n",
      "feature_extractor.Output3.2   -           -        [1, 128, 10, 10]    float32 \n",
      "feature_extractor.Output3.3   147584      -        [1, 128, 5, 5]      float32 \n",
      "feature_extractor.Output3.4   -           -        [1, 128, 5, 5]      float32 \n",
      "feature_extractor.Output4.0   -           -        [1, 128, 5, 5]      float32 \n",
      "feature_extractor.Output4.1   147584      -        [1, 128, 5, 5]      float32 \n",
      "feature_extractor.Output4.2   -           -        [1, 128, 5, 5]      float32 \n",
      "feature_extractor.Output4.3   73792       -        [1, 64, 3, 3]       float32 \n",
      "feature_extractor.Output4.4   -           -        [1, 64, 3, 3]       float32 \n",
      "feature_extractor.Output5.0   -           -        [1, 64, 3, 3]       float32 \n",
      "feature_extractor.Output5.1   73856       -        [1, 128, 3, 3]      float32 \n",
      "feature_extractor.Output5.2   -           -        [1, 128, 3, 3]      float32 \n",
      "feature_extractor.Output5.3   73792       -        [1, 64, 1, 1]       float32 \n",
      "feature_extractor.Output5.4   -           -        [1, 64, 1, 1]       float32 \n",
      "regression_heads.0            18448       -        [1, 16, 38, 38]     float32 \n",
      "classification_heads.0        50732       -        [1, 44, 38, 38]     float32 \n",
      "regression_heads.1            55320       -        [1, 24, 19, 19]     float32 \n",
      "classification_heads.1        152130      -        [1, 66, 19, 19]     float32 \n",
      "regression_heads.2            27672       -        [1, 24, 10, 10]     float32 \n",
      "classification_heads.2        76098       -        [1, 66, 10, 10]     float32 \n",
      "regression_heads.3            27672       -        [1, 24, 5, 5]       float32 \n",
      "classification_heads.3        76098       -        [1, 66, 5, 5]       float32 \n",
      "regression_heads.4            9232        -        [1, 16, 3, 3]       float32 \n",
      "classification_heads.4        25388       -        [1, 44, 3, 3]       float32 \n",
      "regression_heads.5            9232        -        [1, 16, 1, 1]       float32 \n",
      "classification_heads.5        25388       -        [1, 44, 1, 1]       float32 \n",
      "<top-level>:0                 34928       -        [1, 4, 8732]        float32 \n",
      "<top-level>:1                 -           -        [1, 4, 8732]        float32 \n",
      "---                           ---         ---      ---                 ---     \n",
      "Total                         2951858     643      -                   -       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 7), \"This code requires python version >= 3.7\"\n",
    "import functools\n",
    "import time\n",
    "import click\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pprint\n",
    "import tops\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "from ssd.evaluate import evaluate\n",
    "from ssd import utils\n",
    "from tops.config import instantiate\n",
    "from tops import logger, checkpointer\n",
    "from torch.optim.lr_scheduler import ChainedScheduler\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def train_epoch(\n",
    "        model, scaler: torch.cuda.amp.GradScaler,\n",
    "        optim, dataloader_train, scheduler,\n",
    "        gpu_transform: torch.nn.Module,\n",
    "        log_interval: int):\n",
    "    grad_scale = scaler.get_scale()\n",
    "    for batch in tqdm.tqdm(dataloader_train, f\"Epoch {logger.epoch()}\"):\n",
    "        batch = tops.to_cuda(batch)\n",
    "        batch[\"labels\"] = batch[\"labels\"].long()\n",
    "        batch = gpu_transform(batch)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=tops.AMP()):\n",
    "            bbox_delta, confs = model(batch[\"image\"])\n",
    "            loss, to_log = model.loss_func(bbox_delta, confs, batch[\"boxes\"], batch[\"labels\"])\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "        optim.zero_grad()\n",
    "        if grad_scale == scaler.get_scale():\n",
    "            scheduler.step()\n",
    "            if logger.global_step() % log_interval:\n",
    "                logger.add_scalar(\"stats/learning_rate\", scheduler._schedulers[-1].get_last_lr()[-1])\n",
    "        else:\n",
    "            grad_scale = scaler.get_scale()\n",
    "            logger.add_scalar(\"amp/grad_scale\", scaler.get_scale())\n",
    "        if logger.global_step() % log_interval == 0:\n",
    "            to_log = {f\"loss/{k}\": v.mean().cpu().item() for k, v in to_log.items()}\n",
    "            logger.add_dict(to_log)\n",
    "        # torch.cuda.amp skips gradient steps if backward pass produces NaNs/infs.\n",
    "        # If it happens in the first iteration, scheduler.step() will throw exception\n",
    "        logger.step()\n",
    "\n",
    "    return\n",
    "def print_config(cfg):\n",
    "    container = OmegaConf.to_container(cfg)\n",
    "    pp = pprint.PrettyPrinter(indent=2, compact=False)\n",
    "    print(\"--------------------Config file below--------------------\")\n",
    "    pp.pprint(container)\n",
    "    print(\"--------------------End of config file--------------------\")\n",
    "\n",
    "\n",
    "def train(config_path=\"configs/ssd300.py\", evaluate_only = False):\n",
    "    logger.logger.DEFAULT_SCALAR_LEVEL = logger.logger.DEBUG\n",
    "    cfg = utils.load_config(config_path)\n",
    "    print_config(cfg)\n",
    "\n",
    "    tops.init(cfg.output_dir)\n",
    "    tops.set_AMP(cfg.train.amp)\n",
    "    tops.set_seed(cfg.train.seed)\n",
    "    dataloader_train = instantiate(cfg.data_train.dataloader)\n",
    "    dataloader_val = instantiate(cfg.data_val.dataloader)\n",
    "    cocoGt = dataloader_val.dataset.get_annotations_as_coco()\n",
    "    model = tops.to_cuda(instantiate(cfg.model))\n",
    "    optimizer = instantiate(cfg.optimizer, params=utils.tencent_trick(model))\n",
    "    scheduler = ChainedScheduler(instantiate(list(cfg.schedulers.values()), optimizer=optimizer))\n",
    "    checkpointer.register_models(\n",
    "        dict(model=model, optimizer=optimizer, scheduler=scheduler))\n",
    "    total_time = 0\n",
    "    if checkpointer.has_checkpoint():\n",
    "        train_state = checkpointer.load_registered_models(load_best=False)\n",
    "        total_time = train_state[\"total_time\"]\n",
    "        logger.log(f\"Resuming train from: epoch: {logger.epoch()}, global step: {logger.global_step()}\")\n",
    "\n",
    "    gpu_transform_val = instantiate(cfg.data_val.gpu_transform)\n",
    "    gpu_transform_train = instantiate(cfg.data_train.gpu_transform)\n",
    "    evaluation_fn = functools.partial(\n",
    "        evaluate,\n",
    "        model=model,\n",
    "        dataloader=dataloader_val,\n",
    "        cocoGt=cocoGt,\n",
    "        gpu_transform=gpu_transform_val,\n",
    "        label_map=cfg.label_map\n",
    "    )\n",
    "    if evaluate_only:\n",
    "        evaluation_fn()\n",
    "        exit()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=tops.AMP())\n",
    "    dummy_input = tops.to_cuda(torch.randn(1, cfg.train.image_channels, *cfg.train.imshape))\n",
    "    tops.print_module_summary(model, (dummy_input,))\n",
    "    start_epoch = logger.epoch()\n",
    "    for epoch in range(start_epoch, cfg.train.epochs):\n",
    "        start_epoch_time = time.time()\n",
    "        train_epoch(model, scaler, optimizer, dataloader_train, scheduler, gpu_transform_train, cfg.train.log_interval)\n",
    "        end_epoch_time = time.time() - start_epoch_time\n",
    "        total_time += end_epoch_time\n",
    "        logger.add_scalar(\"stats/epoch_time\", end_epoch_time)\n",
    "\n",
    "        eval_stats = evaluation_fn()\n",
    "        eval_stats = {f\"metrics/{key}\": val for key, val in eval_stats.items()}\n",
    "        logger.add_dict(eval_stats, level=logger.logger.INFO)\n",
    "        train_state = dict(total_time=total_time)\n",
    "        checkpointer.save_registered_models(train_state)\n",
    "        logger.step_epoch()\n",
    "    logger.add_scalar(\"stats/total_time\", total_time)\n",
    "\n",
    "\n",
    "train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
